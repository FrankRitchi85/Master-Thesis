{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Age_Young (multiclass).ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"j3F9XXvHL7-6"},"source":["# Set seeds\n","from numpy.random import seed\n","import tensorflow as tf\n","seed(42)\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxgejTaCL7-8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624277785410,"user_tz":-120,"elapsed":619,"user":{"displayName":"Frank Ritchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrcEoyFlw3tH8MpHW9ymQFCDKFX595O5fXVFdvCw=s64","userId":"16336361596461512219"}},"outputId":"5a270d52-6f9c-4ef1-8efb-b9f9fa84b14f"},"source":["# Upgrade module imbalanced-learn to run on Google Colab\n","#!pip install imbalanced-learn --upgrade\n","\n","# Import modules\n","import imblearn\n","import keras\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import pickle\n","import sklearn\n","\n","from google.colab import drive\n","from imblearn.over_sampling import RandomOverSampler\n","from keras.applications.resnet import ResNet50\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, History\n","from keras.layers import Dense, Dropout\n","from keras.layers.normalization import BatchNormalization\n","from keras.metrics import categorical_accuracy\n","from keras.models import Sequential,Model,load_model\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.np_utils import to_categorical\n","from platform import python_version\n","from sklearn.model_selection import train_test_split\n","\n","%matplotlib inline\n","\n","# Versions\n","print(\"Version Python:\",python_version())\n","print()\n","print(\"Version Imbalanced-learn:\",imblearn.__version__)\n","print(\"Version Keras:\",keras.__version__)\n","print(\"Version Matplotlib:\",matplotlib.__version__)\n","print(\"Version NumPy:\",np.__version__)\n","print(\"Version Pandas:\",pd.__version__)\n","print(\"Version Scikit-learn:\",sklearn.__version__)\n","print(\"Version TensorFlow:\",tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Version Python: 3.7.10\n","\n","Version Imbalanced-learn: 0.8.0\n","Version Keras: 2.5.0\n","Version Matplotlib: 3.2.2\n","Version NumPy: 1.19.5\n","Version Pandas: 1.1.5\n","Version Scikit-learn: 0.24.2\n","Version TensorFlow: 2.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YqXeSnObhnW","executionInfo":{"status":"ok","timestamp":1624277790321,"user_tz":-120,"elapsed":503,"user":{"displayName":"Frank Ritchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrcEoyFlw3tH8MpHW9ymQFCDKFX595O5fXVFdvCw=s64","userId":"16336361596461512219"}},"outputId":"e2e00346-9aaf-4844-adc5-c64c2ce5ef9b"},"source":["# Set data folder and read data\n","drive.mount('/content/drive')\n","data_folder = '/content/drive/MyDrive/'\n","data = pd.read_pickle(os.path.join(data_folder, 'data.pkl'))\n","data = data[data[\"age_group\"] == 'Younger']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ppVFOv3aL7--"},"source":["# Setting data augmentation parameters \n","data_augmentation = ImageDataGenerator(\n","    rotation_range = 60,\n","    zoom_range = 0.2,  \n","    width_shift_range = 0.2,\n","    height_shift_range = 0.2,\n","    horizontal_flip = True,  \n","    vertical_flip = True,  \n","    shear_range = 10) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-FXbduSL7--","executionInfo":{"status":"ok","timestamp":1624277797423,"user_tz":-120,"elapsed":313,"user":{"displayName":"Frank Ritchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrcEoyFlw3tH8MpHW9ymQFCDKFX595O5fXVFdvCw=s64","userId":"16336361596461512219"}},"outputId":"b6bd6b0b-2cb9-48ed-ad46-d96de59b38f6"},"source":["# Create training, validation amd test sets (Derived from: https://www.kaggle.com/kaimingk/skin-cancer-mnist-ham10000)\n","\n","# Split 70%, 10%, 20%. Test and validation, together 30%, should be from unique ID's only\n","size_val_test = 0.3 * len(data)\n","val_test_ratio_from_unique = size_val_test/len(data[data.unique == True])\n","\n","# Training data = remainder of unique ID's + non-uniques. Split is stratified by lesion \n","bm_data_train_unique, bm_data_val_test = train_test_split(data[data[\"unique\"] == True], test_size = val_test_ratio_from_unique, stratify=data[data[\"unique\"] == True][\"dx_cat\"], random_state = 42)\n","bm_data_train = pd.concat((bm_data_train_unique, data[data[\"unique\"] == False]), axis = 0)\n","\n","# Split validation and test sets. Split is stratified by lesion \n","bm_data_validation, bm_data_test = train_test_split(bm_data_val_test, test_size = 0.6667, stratify=bm_data_val_test[\"dx_cat\"], random_state = 42)\n","\n","print(\"Training set:   \", round(len(bm_data_train) / len(data)*100,1),\"%\")\n","print(\"Validation set: \", round(len(bm_data_validation) / len(data)*100,1),\"%\")\n","print(\"Testing set:    \", round(len(bm_data_test) / len(data)*100,1),\"%\")\n","print()\n","\n","# Class balancing (random oversampling)\n","X = bm_data_train.drop(['dx_cat'], axis=1)\n","y = bm_data_train['dx_cat']\n","X_test = bm_data_test.drop(['dx_cat'], axis=1)\n","y_test = bm_data_test['dx_cat']\n","\n","ros = RandomOverSampler(random_state=42)\n","X_resampled, y_resampled = ros.fit_resample(X, y)\n","ros = RandomOverSampler(random_state=42)\n","X_test_resampled, y_test_resampled = ros.fit_resample(X_test, y_test)\n","\n","bm_data_train = pd.concat([X_resampled, y_resampled], axis=1)\n","bm_data_test = pd.concat([X_test_resampled, y_test_resampled], axis=1)\n","print('Value counts in training set:')\n","print(bm_data_train['dx_cat'].value_counts())\n","print()\n","print('Value counts in testing set:')\n","print(bm_data_test['dx_cat'].value_counts())\n","\n","# Create feature (x) and target (y) variables (for training, validation and test sets)\n","bm_data_train_x = np.asarray(bm_data_train['image'].tolist())\n","bm_data_validation_x = np.asarray(bm_data_validation['image'].tolist())\n","bm_data_test_x = np.asarray(bm_data_test['image'].tolist())\n","\n","bm_data_train_y = np.asarray(bm_data_train['dx_cat'].tolist())\n","bm_data_validation_y = np.asarray(bm_data_validation['dx_cat'].tolist())\n","bm_data_test_y = np.asarray(bm_data_test['dx_cat'].tolist())\n","\n","# One-hot encoding of target variable\n","bm_num_classes = len(np.sort(data['dx'].unique()))\n","bm_data_train_y = to_categorical(bm_data_train_y, num_classes = bm_num_classes)\n","bm_data_validation_y = to_categorical(bm_data_validation_y, num_classes = bm_num_classes)\n","bm_data_test_y = to_categorical(bm_data_test_y, num_classes = bm_num_classes)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training set:    70.0 %\n","Validation set:  10.0 %\n","Testing set:     20.0 %\n","\n","Value counts in training set:\n","6    2374\n","5    2374\n","4    2374\n","3    2374\n","2    2374\n","1    2374\n","0    2374\n","Name: dx_cat, dtype: int64\n","\n","Value counts in testing set:\n","3    753\n","6    753\n","2    753\n","5    753\n","1    753\n","4    753\n","0    753\n","Name: dx_cat, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HI_3w6DRL7-_"},"source":["# Fit data augmentation\n","data_augmentation.fit(bm_data_train_x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nn9Ury86L7_A","executionInfo":{"status":"ok","timestamp":1624277811160,"user_tz":-120,"elapsed":7799,"user":{"displayName":"Frank Ritchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrcEoyFlw3tH8MpHW9ymQFCDKFX595O5fXVFdvCw=s64","userId":"16336361596461512219"}},"outputId":"708398ab-ddf2-41d5-bc0a-0837e0ff4acd"},"source":["# Creating ResNet model (Derived from: https://www.kaggle.com/jnegrini/ham10000-analysis-and-model-comparison)\n","\n","# Model parameters\n","input_shape = (75, 100, 3)\n","optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","epochs = 50\n","batch_size = 32\n","\n","# Callbacks\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.5, min_lr=0.00001)\n","early_stopping_monitor = EarlyStopping(patience=20,monitor='val_accuracy')\n","history = History()\n","\n","# Define model architecture\n","base_model = ResNet50(include_top=False, input_shape=(75,100, 3),pooling = 'avg', weights = 'imagenet');\n","\n","ResNet50model_multi = Sequential()\n","ResNet50model_multi.add(base_model)\n","ResNet50model_multi.add(Dropout(0.2))\n","ResNet50model_multi.add(Dense(128, activation=\"relu\"))\n","ResNet50model_multi.add(Dropout(0.2))\n","ResNet50model_multi.add(Dense(bm_num_classes, activation = 'softmax'))\n","ResNet50model_multi.summary()\n","\n","# Layers in ResNet are pretrained (ImageNet)\n","for layer in base_model.layers:\n","    layer.trainable = False\n","    \n","ResNet50model_multi.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 1s 0us/step\n","94781440/94765736 [==============================] - 1s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Functional)        (None, 2048)              23587712  \n","_________________________________________________________________\n","dropout (Dropout)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               262272    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 903       \n","=================================================================\n","Total params: 23,850,887\n","Trainable params: 23,797,767\n","Non-trainable params: 53,120\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442},"id":"Ei73TcI4L7_B","executionInfo":{"status":"error","timestamp":1624277930392,"user_tz":-120,"elapsed":119237,"user":{"displayName":"Frank Ritchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrcEoyFlw3tH8MpHW9ymQFCDKFX595O5fXVFdvCw=s64","userId":"16336361596461512219"}},"outputId":"04a8eaba-aff0-4389-b9d0-81ce1bdd7c2c"},"source":["# Fit and save model\n","bm_history = ResNet50model_multi.fit(data_augmentation.flow(bm_data_train_x,bm_data_train_y, batch_size=batch_size),\n","                        epochs = epochs, validation_data = (bm_data_validation_x,bm_data_validation_y),\n","                        verbose = 1, steps_per_epoch=bm_data_train_x.shape[0] // batch_size, \n","                        callbacks=[learning_rate_reduction,early_stopping_monitor, history])\n","\n","ResNet50model_multi.save(os.path.join(data_folder,\"Age_Young_multi_model\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","519/519 [==============================] - 93s 80ms/step - loss: 1.2164 - accuracy: 0.5474 - val_loss: 0.6346 - val_accuracy: 0.7761\n","Epoch 2/50\n","361/519 [===================>..........] - ETA: 10s - loss: 0.6910 - accuracy: 0.7351"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-4039f523961c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbm_data_validation_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbm_data_validation_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbm_data_train_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         callbacks=[learning_rate_reduction,early_stopping_monitor, history])\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mResNet50model_multi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Age_Young_multi_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"3F8PEgx5L7_B"},"source":["# Accuracy over epochs\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy - Age_Young (multiclass)')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper right')\n","filename = str('Model Accuracy - Age_Young (multiclass).png')\n","plt.savefig(os.path.join(data_folder,filename), dpi=600)\n","plt.show()\n","\n","# Loss over epochs\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss - Age_Young (multiclass)')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper right')\n","filename = str('Model Loss - Age_Young (multiclass).png')\n","plt.savefig(os.path.join(data_folder,filename), dpi=600)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7gt-9aaBL7_C"},"source":["with open(os.path.join(data_folder, 'data_bm_age_young.pkl'), 'wb') as f:\n","    pickle.dump([bm_data_train_x,bm_data_validation_x,bm_data_test_x,bm_data_train_y,bm_data_validation_y,bm_data_test_y], f)"],"execution_count":null,"outputs":[]}]}